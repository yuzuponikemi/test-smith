"""
Provenanceæ©Ÿèƒ½ã®ã‚¯ã‚¤ãƒƒã‚¯ãƒ‡ãƒ¢

æ—¢å­˜ã®ãƒ¬ãƒãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã—ã¦ã€Provenanceæ©Ÿèƒ½ã‚’ç´ æ—©ãå®Ÿæ¼”ã—ã¾ã™ã€‚
"""

import json
from pathlib import Path
from datetime import datetime


def load_latest_report_data():
    """æœ€æ–°ã®ãƒ†ã‚¹ãƒˆãƒ¬ãƒãƒ¼ãƒˆã‹ã‚‰ã‚½ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€"""

    # Ultimate testã®çµæœã‚’ä½¿ç”¨ (script is in examples/provenance/)
    report_file = Path("../../reports/report_20251202_230148_simple_Ultimate_test_complete_citation_system_verificati.md")

    if not report_file.exists():
        print(f"âŒ ãƒ¬ãƒãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {report_file}")
        return None

    # ãƒ¬ãƒãƒ¼ãƒˆã‚’èª­ã¿è¾¼ã¿
    with open(report_file) as f:
        report_content = f.read()

    # Simulate state (å®Ÿéš›ã®å®Ÿè¡Œã‹ã‚‰ã‚½ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ã‚’å†æ§‹ç¯‰)
    # Note: å®Ÿéš›ã®ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã§ã¯graph.invoke()ã‹ã‚‰å–å¾—
    mock_state = {
        "query": "Ultimate test: complete citation system verification",
        "report": report_content,
        "web_sources": generate_mock_web_sources(35),
        "rag_sources": generate_mock_rag_sources(35)
    }

    return mock_state


def generate_mock_web_sources(count: int):
    """ãƒ¢ãƒƒã‚¯Webã‚½ãƒ¼ã‚¹ã‚’ç”Ÿæˆï¼ˆãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ï¼‰"""
    sources = []
    for i in range(1, count + 1):
        sources.append({
            "source_id": f"web_{i}",
            "source_type": "web",
            "title": f"Citation Verification Best Practices {i}",
            "url": f"https://example.com/citation-research-{i}",
            "content_snippet": f"This article discusses citation verification methods and their importance in academic research. Key findings include...",
            "relevance_score": 0.85 - (i * 0.01),
            "query_used": "citation verification best practices",
            "timestamp": datetime.now().isoformat()
        })
    return sources


def generate_mock_rag_sources(count: int):
    """ãƒ¢ãƒƒã‚¯KBã‚½ãƒ¼ã‚¹ã‚’ç”Ÿæˆï¼ˆãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ï¼‰"""
    sources = []
    kb_files = [
        "Causal Inference with Large Language Model A Survey.md",
        "Enhancing Ontologies with Large Language Models.pdf",
        "rough-alignment-algorithms-full-workflow.md"
    ]

    for i in range(1, count + 1):
        sources.append({
            "source_id": f"rag_{i}",
            "source_type": "rag",
            "title": f"Internal Documentation: Citation Systems Part {i}",
            "content_snippet": f"Our internal documentation on citation management systems highlights the importance of accuracy and consistency...",
            "relevance_score": 0.80 - (i * 0.015),
            "query_used": "citation system documentation",
            "timestamp": datetime.now().isoformat(),
            "metadata": {
                "source_file": f"documents/{kb_files[i % len(kb_files)]}",
                "chunk_index": i,
                "full_content_length": 1500
            }
        })
    return sources


def export_citations_simple(state: dict, format: str = "bibtex"):
    """å¼•ç”¨ã‚’æŒ‡å®šã•ã‚ŒãŸãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã§ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆï¼ˆç°¡æ˜“ç‰ˆï¼‰"""

    web_sources = state.get("web_sources", [])
    rag_sources = state.get("rag_sources", [])
    all_sources = web_sources + rag_sources

    if format == "bibtex":
        entries = []
        year = datetime.now().year

        for i, source in enumerate(all_sources[:5], 1):  # æœ€åˆã®5ã¤
            source_type = source.get("source_type", "misc")
            title = source.get("title", "Unknown")
            url = source.get("url")

            key = f"source{year}_{i}"

            if source_type == "web" and url:
                entry = f"""@online{{{key},
  title = {{{title}}},
  url = {{{url}}},
  year = {{{year}}},
  note = {{Accessed: {datetime.now().strftime('%Y-%m-%d')}}}
}}"""
            else:
                file_path = source.get("metadata", {}).get("source_file", "Unknown")
                entry = f"""@techreport{{{key},
  title = {{{title}}},
  institution = {{Internal Knowledge Base}},
  year = {{{year}}},
  note = {{Source: {file_path}}}
}}"""

            entries.append(entry)

        return "\n\n".join(entries)

    elif format == "apa":
        citations = []
        year = datetime.now().year

        for i, source in enumerate(all_sources[:5], 1):
            title = source.get("title", "Unknown")
            source_type = source.get("source_type", "misc")
            url = source.get("url")

            if source_type == "web" and url:
                citation = f"{i}. {title}. ({year}). Retrieved from {url}"
            else:
                file_path = source.get("metadata", {}).get("source_file", "Unknown")
                citation = f"{i}. {title}. ({year}). Internal Knowledge Base. Source: {file_path}"

            citations.append(citation)

        return "\n\n".join(citations)

    elif format == "mla":
        citations = []
        access_date = datetime.now().strftime("%d %b. %Y")

        for i, source in enumerate(all_sources[:5], 1):
            title = source.get("title", "Unknown")
            source_type = source.get("source_type", "misc")
            url = source.get("url")

            if source_type == "web" and url:
                citation = f'{i}. "{title}." Web. {access_date}. <{url}>.'
            else:
                file_path = source.get("metadata", {}).get("source_file", "Unknown")
                citation = f'{i}. "{title}." Internal Knowledge Base. {access_date}. Source: {file_path}.'

            citations.append(citation)

        return "\n\n".join(citations)


def query_claim_provenance_simple(state: dict, claim: str):
    """ç‰¹å®šã®ä¸»å¼µã®ã‚½ãƒ¼ã‚¹ã‚’æ¤œç´¢ï¼ˆç°¡æ˜“ç‰ˆï¼‰"""

    report = state.get("report", "")
    web_sources = state.get("web_sources", [])
    rag_sources = state.get("rag_sources", [])
    all_sources = web_sources + rag_sources

    # ãƒ¬ãƒãƒ¼ãƒˆå†…ã§ä¸»å¼µã‚’æ¤œç´¢
    claim_lower = claim.lower()
    report_lower = report.lower()

    if claim_lower not in report_lower:
        return {
            "claim": claim,
            "found": False,
            "message": "ä¸»å¼µãŒãƒ¬ãƒãƒ¼ãƒˆå†…ã«è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ"
        }

    # ä¸»å¼µã®å‘¨è¾ºãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—
    pos = report_lower.index(claim_lower)
    start = max(0, pos - 150)
    end = min(len(report), pos + len(claim) + 150)
    context = report[start:end]

    # å¼•ç”¨ç•ªå·ã‚’æ¤œç´¢ [1], [2], etc.
    import re
    citation_pattern = r'\[(\d+)\]'
    citations = []

    for match in re.finditer(citation_pattern, context):
        cite_num = int(match.group(1))
        if 1 <= cite_num <= len(all_sources):
            source = all_sources[cite_num - 1]
            citations.append({
                "number": cite_num,
                "title": source.get("title", "Unknown"),
                "type": source.get("source_type", "unknown"),
                "relevance": source.get("relevance_score", 0.5)
            })

    return {
        "claim": claim,
        "found": True,
        "context": context,
        "citations": citations,
        "source_count": len(citations)
    }


def main():
    """ãƒ¡ã‚¤ãƒ³ãƒ‡ãƒ¢å®Ÿè¡Œ"""

    print("=" * 80)
    print("ğŸ”¬ Test-Smith Provenanceæ©Ÿèƒ½ - ã‚¯ã‚¤ãƒƒã‚¯ãƒ‡ãƒ¢")
    print("=" * 80)
    print()

    # Step 1: ãƒ¬ãƒãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿
    print("ğŸ“‚ æ—¢å­˜ã®ãƒ¬ãƒãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ä¸­...")
    state = load_latest_report_data()

    if not state:
        print("âŒ ãƒ¬ãƒãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ")
        return

    print("âœ… ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å®Œäº†\n")

    # Step 2: ã‚½ãƒ¼ã‚¹çµ±è¨ˆã‚’è¡¨ç¤º
    print("=" * 80)
    print("ğŸ“ˆ ã‚½ãƒ¼ã‚¹çµ±è¨ˆ")
    print("=" * 80)
    print()

    web_sources = state.get("web_sources", [])
    rag_sources = state.get("rag_sources", [])

    print(f"ç·ã‚½ãƒ¼ã‚¹æ•°: {len(web_sources) + len(rag_sources)}")
    print(f"  - Web sources: {len(web_sources)}")
    print(f"  - Knowledge Base sources: {len(rag_sources)}")
    print()

    # Top 3 Web sources
    print("ğŸŒ Top 3 Web Sources:")
    for source in web_sources[:3]:
        print(f"  â€¢ {source['title']}")
        print(f"    URL: {source['url']}")
        print(f"    Relevance: {source['relevance_score']:.2f}\n")

    # Top 3 KB sources
    print("ğŸ“š Top 3 Knowledge Base Sources:")
    for source in rag_sources[:3]:
        print(f"  â€¢ {source['title']}")
        print(f"    File: {source['metadata']['source_file']}")
        print(f"    Relevance: {source['relevance_score']:.2f}\n")

    # Step 3: ç‰¹å®šã®ä¸»å¼µã®æ ¹æ‹ ã‚’ç¢ºèª
    print("=" * 80)
    print("ğŸ” ç‰¹å®šã®ä¸»å¼µã®æ ¹æ‹ ã‚’ç¢ºèª")
    print("=" * 80)
    print()

    claim_to_check = "Inaccurate citations can lead to errors"
    print(f"ç¢ºèªã™ã‚‹ä¸»å¼µ: \"{claim_to_check}\"")
    print()

    provenance = query_claim_provenance_simple(state, claim_to_check)

    if provenance.get("found"):
        print(f"âœ… ä¸»å¼µã‚’ç™ºè¦‹")
        print(f"ğŸ“š æ”¯æŒã‚½ãƒ¼ã‚¹æ•°: {provenance['source_count']}")
        print()

        if provenance.get("citations"):
            print("ğŸ’¡ ã“ã®ä¸»å¼µã‚’æ”¯æŒã™ã‚‹ã‚½ãƒ¼ã‚¹:")
            for citation in provenance["citations"][:3]:
                print(f"  [{citation['number']}] {citation['title']}")
                print(f"      Type: {citation['type']}")
                print(f"      Relevance: {citation['relevance']:.2f}\n")
    else:
        print(f"âŒ {provenance.get('message')}")

    # Step 4: å¼•ç”¨ã‚’è¤‡æ•°ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã§ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
    print("=" * 80)
    print("ğŸ“„ å¼•ç”¨ã‚’ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ (æœ€åˆã®5ã‚¨ãƒ³ãƒˆãƒªã®ã¿)")
    print("=" * 80)
    print()

    # BibTeX
    print("ğŸ“– BibTeXå½¢å¼:")
    print("-" * 80)
    bibtex = export_citations_simple(state, format="bibtex")
    print(bibtex)
    print()

    # APA
    print("ğŸ“˜ APAå½¢å¼:")
    print("-" * 80)
    apa = export_citations_simple(state, format="apa")
    print(apa)
    print()

    # MLA
    print("ğŸ“— MLAå½¢å¼:")
    print("-" * 80)
    mla = export_citations_simple(state, format="mla")
    print(mla)
    print()

    # Step 5: å¼•ç”¨ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
    print("=" * 80)
    print("ğŸ’¾ å¼•ç”¨ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ")
    print("=" * 80)
    print()

    with open("../../citations/demo_citations_quick_bibtex.bib", "w") as f:
        f.write(export_citations_simple(state, format="bibtex"))
    print("âœ… BibTeXå¼•ç”¨ã‚’ä¿å­˜: citations/demo_citations_quick_bibtex.bib")

    with open("../../citations/demo_citations_quick_apa.txt", "w") as f:
        f.write(export_citations_simple(state, format="apa"))
    print("âœ… APAå¼•ç”¨ã‚’ä¿å­˜: citations/demo_citations_quick_apa.txt")

    with open("../../citations/demo_citations_quick_mla.txt", "w") as f:
        f.write(export_citations_simple(state, format="mla"))
    print("âœ… MLAå¼•ç”¨ã‚’ä¿å­˜: citations/demo_citations_quick_mla.txt")

    # ã‚µãƒãƒªãƒ¼
    print("\n" + "=" * 80)
    print("ğŸ‰ ãƒ‡ãƒ¢å®Œäº†ï¼")
    print("=" * 80)
    print()
    print("ç”Ÿæˆã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«:")
    print("  1. citations/demo_citations_quick_bibtex.bib - BibTeXå½¢å¼ã®å¼•ç”¨")
    print("  2. citations/demo_citations_quick_apa.txt - APAå½¢å¼ã®å¼•ç”¨")
    print("  3. citations/demo_citations_quick_mla.txt - MLAå½¢å¼ã®å¼•ç”¨")
    print()
    print("ğŸ’¡ Provenanceæ©Ÿèƒ½ã®ä½¿ã„æ–¹:")
    print()
    print("  # Pythonã‚³ãƒ¼ãƒ‰ä¾‹:")
    print("  from src.provenance import query_claim_provenance, export_citations")
    print()
    print("  # ç ”ç©¶å®Ÿè¡Œå¾Œ")
    print('  result = graph.invoke({"query": "Your query"})')
    print()
    print("  # ä¸»å¼µã®æ ¹æ‹ ã‚’ç¢ºèª")
    print('  explanation = query_claim_provenance(result, "specific claim")')
    print()
    print("  # å¼•ç”¨ã‚’ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ")
    print('  bibtex = export_citations(result, format="bibtex")')
    print('  apa = export_citations(result, format="apa")')
    print('  mla = export_citations(result, format="mla")')
    print()


if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\n\nâš ï¸  ãƒ‡ãƒ¢ãŒä¸­æ–­ã•ã‚Œã¾ã—ãŸ")
    except Exception as e:
        print(f"\n\nâŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        import traceback
        traceback.print_exc()
