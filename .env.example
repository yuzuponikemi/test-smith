# Test-Smith Environment Configuration
# Copy this file to .env and fill in your API keys

# ============================================
# LangSmith Tracing (for monitoring & debugging)
# ============================================
LANGCHAIN_TRACING_V2="true"
LANGCHAIN_API_KEY="<your-langsmith-api-key>"
LANGCHAIN_PROJECT="deep-research-v1-proto"

# ============================================
# Tavily API (for web search)
# ============================================
TAVILY_API_KEY="<your-tavily-api-key>"

# ============================================
# Claude/Anthropic Configuration
# ============================================
# Set USE_CLAUDE=true to switch from Ollama to Claude models
USE_CLAUDE="false"

# Your Anthropic API key (required when USE_CLAUDE=true)
# Get your key from: https://console.anthropic.com/settings/keys
ANTHROPIC_API_KEY="<your-anthropic-api-key>"

# ============================================
# Model Selection Notes
# ============================================
# When USE_CLAUDE=true, the system uses:
# - Planner: claude-3-5-haiku (fast query planning)
# - Master Planner: claude-sonnet-4-5 (hierarchical decomposition)
# - Reflection: claude-3-5-haiku (self-evaluation)
# - Evaluation: claude-3-5-sonnet (depth assessment)
# - Analyzer: claude-sonnet-4-5 (result processing)
# - Synthesizer: claude-sonnet-4-5 (final report generation)
#
# When USE_CLAUDE=false (default), uses local Ollama models:
# - llama3, command-r
